kurtosis((mTDI$TDIm^2))
mTDI$TDIm_norm <- mTDI$TDIm^2
#model nullp
nullp<- glm(TDIm_norm ~ 1  , family =gaussian, data = mTDI)
#modeles avec que les main effects
fullp <- glm(TDIm_norm~risk*hab_video, data=mTDI, family="gaussian")
#model selection using AIC in forward selection
mod1<-stepAIC(nullp, scope = list(lower = nullp, upper = fullp),  direction = "forward")
#model selection using BIC in forward selection
mod2<-stepAIC(nullp, scope = list(lower = nullp, upper = fullp), direction = "forward", k=log(nobs(fullp)))
## CHOSING MODEL (based on its predictive power)
# calcul du mae entre obs et pred, la valeur doit etre la plus petite  possible
val13<-NA
val14<-NA
val13<-mean(abs(mTDI$TDIm_norm-predict(mod1, newdata = mTDI, type = "response")),na.rm=T)
val14<-mean(abs(mTDI$TDIm_norm-predict(mod2, newdata = mTDI, type = "response")),na.rm=T)
# le modele avec les valeurs les plus basses est le meilleur
mae<-c(val13, val14) ## ici c'est mod1 qui a la plus petite valeur
#compute  r2 between fitted and observed, the best model has the highest value
val13<-NA
val14<-NA
val13<-costr2(mTDI$TDIm_norm,predict(mod1, newdata = mTDI, type = "response"))
val14<-costr2(mTDI$TDIm_norm,predict(mod2, newdata = mTDI, type = "response"))
r2<-c(val13, val14)  ### ici c'est le mod1 qui a la plus haute valeur
plot(mae,r2)
text(mae,r2,seq(1:length(mae)),pos = 1)
coef(mod1)
summary(mod1)
adjr2<-modar2(mod1,mTDI,mTDI$TDIm_norm)
adjr2
# Variable les plus explicatives
summary(mod1)
anova(mod1, test="Chisq")
anova(nullp,mod1, test="Chisq")
## manche ##
hist(mTDI_manche$TDIm)
skewness((mTDI_manche$TDIm))
kurtosis((mTDI_manche$TDIm))
#model nullp
nullp<- glm(TDIm ~ 1  , family =gaussian, data = mTDI_manche)
#modeles avec que les main effects
fullp <- glm(TDIm~risk*hab_video, data=mTDI_manche, family="gaussian")
#model selection using AIC in forward selection
mod1<-stepAIC(nullp, scope = list(lower = nullp, upper = fullp),  direction = "forward")
#model selection using BIC in forward selection
mod2<-stepAIC(nullp, scope = list(lower = nullp, upper = fullp), direction = "forward", k=log(nobs(fullp)))
## CHOSING MODEL (based on its predictive power)
# calcul du mae entre obs et pred, la valeur doit etre la plus petite  possible
val13<-NA
val14<-NA
val13<-mean(abs(mTDI_manche$TDIm-predict(mod1, newdata = mTDI_manche, type = "response")),na.rm=T)
val14<-mean(abs(mTDI_manche$TDIm-predict(mod2, newdata = mTDI_manche, type = "response")),na.rm=T)
# le modele avec les valeurs les plus basses est le meilleur
mae<-c(val13, val14) ## ici c'est mod1 qui a la plus petite valeur
#compute  r2 between fitted and observed, the best model has the highest value
val13<-NA
val14<-NA
val13<-costr2(mTDI_manche$TDIm,predict(mod1, newdata = mTDI_manche, type = "response"))
val14<-costr2(mTDI_manche$TDIm,predict(mod2, newdata = mTDI_manche, type = "response"))
r2<-c(val13, val14)  ### ici c'est le mod1 qui a la plus haute valeur
plot(mae,r2)
text(mae,r2,seq(1:length(mae)),pos = 1)
coef(mod1)
summary(mod1)
adjr2<-modar2(mod1,mTDI_manche,mTDI_manche$TDIm_norm)
adjr2
# Variable les plus explicatives
summary(mod1)
anova(mod1, test="Chisq")
anova(nullp,mod1, test="Chisq")
## medit ##
hist(mTDI_medit$TDIm^2)
skewness((mTDI_medit$TDIm^2))
kurtosis((mTDI_medit$TDIm^2))
mTDI_medit$TDIm_norm <- mTDI_medit$TDIm^2
mTDI_medit
?stepAIC
### GLM après réallocation pour faire la sensi
# seules les abondances des groupes A et B ont changé avec la réallocation
setwd("C://Users/cjac/Desktop")
# données (résultats de la réallocation st ds comDens3)
load("C://Users/cjac/Desktop/data1304.RData")
load("C://Users/cjac/Desktop/RDA réallocation Kmeans.RData") # Kmeans (4 grps)
#### calcule des abondance et densité des groupes sensi ####
# densité
sensiA<-comDens3[,c(7,13,14,17,20,21,24,29)]
sensiA$SomDensGprA<-apply(sensiA,1,sum)
sensiB<-comDens3[,c(2,5,6,8,9,10,11,12,16,18,19,22,25,26,27,28,31,32,33,34,35,36,37,38,40)]
sensiB$SomDensGprB<-apply(sensiB,1,sum)
sensiC<-comDens3[,c(4,15,30,39)]
sensiC$SomDensGprC<-apply(sensiC,1,sum)
sensiD<-comDens3[,c(3,23)]
sensiD$SomDensGprD<-apply(sensiD,1,sum)
SensiDensRealloc<-cbind.data.frame(sensiA$SomDensGprA, sensiB$SomDensGprB, sensiC$SomDensGprC, sensiD$SomDensGprD)
colnames(SensiDensRealloc)<-c("GrpA","GrpB","GrpC","GrpD")
# abondance
sensiA<-comAbond3[,c(7,13,14,17,20,21,24,29)]
sensiA$id<-as.matrix(rep(1,152))
sum<-aggregate(sensiA,by=list(sensiA$id),sum)
sum<-sum[,-c(1,10)]
sumt<-as.data.frame(t(sum))
sumt$names<-rownames(sumt)
colnames(sumt)<-c("Abundances","Taxa")
p <- ggplot(sumt, aes(x=Taxa, y=Abundances)) + geom_bar(stat="identity",position="dodge")
p + theme(axis.text.x = element_text(angle=90),axis.text.y = element_text(angle=90)) + ggtitle("Group A")
sensiA$SomAbondGprA<-apply(sensiA,1,sum)
sensiB<-comAbond3[,c(2,5,6,8,9,10,11,12,16,18,19,22,25,26,27,28,31,32,33,34,35,36,37,38,40)]
sensiB$id<-as.matrix(rep(1,152))
sum<-aggregate(sensiB,by=list(sensiB$id),sum)
sum<-sum[,-c(1,27)]
sumt<-as.data.frame(t(sum))
sumt$names<-rownames(sumt)
colnames(sumt)<-c("Abundances","Taxa")
p <- ggplot(sumt, aes(x=Taxa, y=Abundances)) + geom_bar(stat="identity",position="dodge")
p + theme(axis.text.x = element_text(angle=90),axis.text.y = element_text(angle=90)) + ggtitle("Group B")
sensiB$SomAbondGprB<-apply(sensiB,1,sum)
sensiC<-comAbond3[,c(4,15,30,39)]
sensiC$id<-as.matrix(rep(1,152))
sum<-aggregate(sensiC,by=list(sensiC$id),sum)
sum<-sum[,-c(1,6)]
sumt<-as.data.frame(t(sum))
sumt$names<-rownames(sumt)
colnames(sumt)<-c("Abundances","Taxa")
p <- ggplot(sumt, aes(x=Taxa, y=Abundances)) + geom_bar(stat="identity",position="dodge")
p + theme(axis.text.x = element_text(angle=90),axis.text.y = element_text(angle=90)) + ggtitle("Group C")
sensiC$SomAbondGprC<-apply(sensiC,1,sum)
sensiD<-comAbond3[,c(3,23)]
sensiD$id<-as.matrix(rep(1,152))
sum<-aggregate(sensiD,by=list(sensiD$id),sum)
sum<-sum[,-c(1,4)]
sumt<-as.data.frame(t(sum))
sumt$names<-rownames(sumt)
colnames(sumt)<-c("Abundances","Taxa")
p <- ggplot(sumt, aes(x=Taxa, y=Abundances)) + geom_bar(stat="identity",position="dodge")
p + theme(axis.text.x = element_text(angle=90),axis.text.y = element_text(angle=90)) + ggtitle("Group D")
sensiD$SomAbondGprD<-apply(sensiD,1,sum)
SensiAbondRealloc<-cbind.data.frame(sensiA$SomAbondGprA, sensiB$SomAbondGprB, sensiC$SomAbondGprC, sensiD$SomAbondGprD)
colnames(SensiAbondRealloc)<-c("GrpA","GrpB","GrpC","GrpD")
#### GLM groupes sensi ####
#load fonctions perso Sandrine
source("~/Documents/doc stage master2/GLM habitat sensibilite/mestitfonctions.R")
## Packages
library(car)
library(MASS)
library(boot)
library(verification)
library(PresenceAbsence)
library(spdep)
library(plotrix)
library(effects)
library(AER) # test de disperison
library(moments) #test skewness and kurtosis
library(fitdistrplus)
##### Groupe de sensibilité A (abondance) ####
# resultats
load("C://Users/cjac/Desktop/Sensi réalloc grpA.RData")
dataSen<-cbind.data.frame(SensiAbondRealloc$GrpA ,comDens2[,c("code","Mid_Lon","Mid_Lat","Water_Depth")],comEffDeci[,4:9])
colnames(dataSen)<-c("Sensi","Sed","Lon","Lat","Water_Depth","chalut38","chalut1439","filet38","filet1439","autre38","autre1439")
# Collinéarité des variables
vif(lm(Sensi ~ Lat + Water_Depth + Lon + chalut1439 + Lat*Lat + Lon*Lon + Lat*Lon+ Water_Depth*Water_Depth + chalut1439*chalut1439 , data=dataSen))
vif(lm(Sensi ~ Lat + Water_Depth + chalut1439 + Lat*Lat + Water_Depth*Water_Depth + chalut1439*chalut1439 , data=dataSen))
# retirer longitude
## GLM habitat model****************************************************************************
# recherche de la fonction de lien la plus adaptée
hist(dataSen$Sensi, breaks="Sturges", col="darkgray", main="Histogramme Sensibilité groupe 1")# distribution de poisson
test<- glm(Sensi ~ Sed  +  Water_Depth + chalut38 + chalut1439 + filet38 + filet1439 + autre38 + autre1439 + Lat , family = poisson, data = dataSen)
mean(dataSen$Sensi)
var(dataSen$Sensi)# la variance est plus de 6 fois la moyenne. Donc pas de poisson, car on a pas la moy=var
dispersiontest(test, trafo = 1)# surdispersion dans l'abondance, on utilise glm.nb.
# Rajouter des variables au second degrés pour évaluer les relations non linéaires
dataSen$Lat2<- (dataSen$Lat)^2
dataSen$Water_Depth2<-(dataSen$Water_Depth)^2
dataSen$chalut14392<-(dataSen$chalut1439)^2
dataSen$chalut382<-(dataSen$chalut38)^2
dataSen$filet14392<-(dataSen$filet1439)^2
dataSen$filet382<-(dataSen$filet38)^2
dataSen$autre14392<-(dataSen$autre1439)^2
dataSen$autre382<-(dataSen$autre38)^2
##GLM modelling********************************************************************************
## model null (glm.nb et utilisation de poisson même si ce n'est plus des entiers, c'est toujours un compte)
#http://stats.stackexchange.com/questions/70054/how-is-it-possible-that-poisson-glm-accepts-non-integer-numbers
#http://stats.stackexchange.com/questions/164889/how-to-deal-with-non-integer-warning-from-negative-binomial-glm?rq=1
null<- glm.nb(Sensi ~ 1, data = dataSen)
full2 <- glm.nb(Sensi ~ Sed + Water_Depth + chalut1439 + Lat + Water_Depth2 + chalut14392 + Lat2 + chalut1439*Water_Depth + Sed*chalut1439 + Sed*Water_Depth, data = dataSen)
#model selection using AIC in "both" ways selection
glmSensi13<-stepAIC(null, scope = list(lower = null, upper = full2),  direction = "both")
#model selection using BIC in "both"ways selection
glmSensi14<-stepAIC(null, scope = list(lower = null, upper = full2), direction = "both", k=log(nobs(full2)))
## CHOSING MODEL (based on its predictive power)
# calcul du mae entre obs et pred, la valeur doit etre la plus petite  possible
val13<-NA
val14<-NA
val13<-mean(abs(dataSen$Sensi-predict(glmSensi13, newdata = dataSen, type = "response")),na.rm=T)
val14<-mean(abs(dataSen$Sensi-predict(glmSensi14, newdata = dataSen, type = "response")),na.rm=T)
# le modele avec les valeurs les plus basses est le meilleur
mae<-c(val13, val14)
#compute  r2 between fitted and observed, the best model has the highest value
val13<-NA
val14<-NA
val13<-costr2(dataSen$Sensi,predict(glmSensi13, newdata = dataSen, type = "response"))
val14<-costr2(dataSen$Sensi,predict(glmSensi14, newdata = dataSen, type = "response"))
#on regarde les resultats des val.
#le modele avec les valeurs les plus hautes est le meilleur
r2<-c(val13, val14)
#on projette l'erreur vs le r2
plot(mae,r2)
text(mae,r2,seq(1:length(mae)),pos = 1)
coef(glmSensi13)
summary(glmSensi13)
adjr2<-modar2(glmSensi13,dataSen,dataSen$Sensi)
adjr2
coef(glmSensi14)
summary(glmSensi14)
adjr2<-modar2(glmSensi14,dataSen,dataSen$Sensi)
adjr2
## diagramme de Taylor:
# provide a way of graphically summarizing how closely a pattern (or a set of patterns) matches observations. The similarity between two patterns is quantified in terms of their correlation
# their centered root-mean-square difference and the amplitude of their variations (represented by their standard deviations). These diagrams are especially useful in evaluating multiple aspects
# of complex models or in gauging the relative skill of many different models (e.g., IPCC, 2001).
mat<-cbind(dataSen$Sensi,predict(glmSensi13, newdata = dataSen, type = "response"),predict(glmSensi14, newdata = dataSen, type = "response"))
taylor.diagram(mat[,1],mat[,2], show.gamma=TRUE,ngamma=10,sd.arcs=T,ref.sd=T ,pch="1",normalize=T)
taylor.diagram(mat[,1],mat[,3],add=TRUE,pch="2",col="blue",normalize=T)
setwd("C://Users/cjac/Desktop/") ## charger le dossier dans lequel on travaille
##### Chargement des tableaux de données ###
donnee_medits200 <- read.table("data_bio.csv", header=T, sep=";", dec=".") ## fichier espèces
setwd("C://Users/cjac/Desktop/scripts_example/") ## charger le dossier dans lequel on travaille
##### Chargement des tableaux de données ###
donnee_medits200 <- read.table("data_bio.csv", header=T, sep=";", dec=".") ## fichier espèces
param <- read.table("caracteristics_stations.csv", sep=";", dec=".", header=T)  ### fichier position des traits de chalut
TDI<- read.table("TDI_all.csv", sep=";", dec=",", header=T)  ## fichier traits biologiques/espèces
###### Correspondance entre le fichier final et la base de données des traits des espèces
### merge catch and tdi
TDI$Taxon <- as.character(TDI$Taxon)
tab<- merge(donnee_medits200,TDI, by.x="taxon", by.y="Taxon", all.x=T, all.y=F)
tab
#### quels sont les taxons où il manque le tdi
tab$taxon<- as.character(tab$taxon)
tabx<-tab[which(is.na(tab$Mobility)),]
b<-unique(tabx$taxon)  #### nom des taxons n'ayant pas de traits
a<-merge(tabx, TDI, by.x="taxon", by.y="Family", all.x=T, all.y=F)
match(b, TDI$Family) ### ici on fait au niveau de la famille mais on peut le faire au niveau taxonomique que l'on veut
pb <- c()  #### création d'un vecteur vide pb
for(i in 1:length(b)){
taxon=b[i]     #### taxon = nom des taxons n'ayant pas de traits
Trait = TDI[which(TDI$Family==taxon),c(7:11)] #### création du data frame Trait qui prends les valeurs de traits si la famille est retrouvée dans la catégorie famille du tbaleau TDI
Trait=unique(Trait)  ### permet de garder "qu'un exemplaire" des diférences
if(nrow(Trait)==1){tab[which(tab$taxon==taxon), c(18:23)]<- Trait}  ### Trait comporte qu'une ligne alors on peut lui attribuer les valeurs de Trait
if(nrow(Trait)>1){  #### Trait comporte plusieurs lignes
if(as.numeric(apply(Trait[1:5],2, sd))[1]<1.5 & as.numeric(apply(Trait,2, sd))[2]<1.5 & as.numeric(apply(Trait,2, sd))[3]<1.5 & as.numeric(apply(Trait,2, sd))[4]<1.5 & as.numeric(apply(Trait,2, sd))[5]<1.5)   {  ### l'écart type de chaque trait doit être inférieur à 1.5
if(sd(as.numeric(apply(Trait,1, sum)))<2.5){   #### l'écart type de la somme des traits (donc du TDI) doit être inférieur à 2.5
pb <- rbind(pb, taxon)  #### tout les taxons qui répondent à ces conditions vont se retrouver dans pb
Trait[nrow(Trait)+1,] <-apply(Trait,2,max)  #### si toutes ces conditions réunient alors on peut prendre la valeur maximale pour chaque trait et l'attribuer à la famille
tab[which(tab$taxon==taxon), c(18:24)]<- Trait[nrow(Trait),]  #### et on peut le remettre dans le tableau du départ
}
}
}
}
pb<- tab[which(is.na(tab$Mobility)),]
pb
### vérification de la proportion de sp enlever apr station
w<- ddply(tab, .variables="code_trait", summarize, biom_tot= sum(biom1km))
q<- merge(pb, w, by="code_trait")
p <- ddply(q, .variables = "code_trait", summarize, biom_enl=sum(biom1km))
q<- merge(p, w, by="code_trait")
q$prop <- (q$biom_enl/q$biom_tot)*100
q<- subset(q, prop >= 25) ### on conserve que les taxons où moins de 25% de la biomasse a été supprimée par manque d'info
i<-unique(q$code_trait)
tab<- subset(tab, !code_trait %in% i)
#### suppression des taxons où les traits sont encore vides
if (length(pb)>0) tab <- tab[-which(is.na(tab$Mobility)),] else tab <- tab
# création de la colonne tdi
tab$TDI<-tab$Mobility + tab$Fragility + tab$Position + tab$Size + tab$Feeding.mode
# aggregate tab by trait, année et taxon
Newtab<- aggregate(biom1km ~ code_trait + Annee + taxon , data = tab, sum)
#compute total catch by trait et année
Tot<- aggregate(biom1km ~ code_trait + Annee   , data = Newtab, sum)
#compute relative biomass
Newtab<-merge(Newtab, Tot, by=c("code_trait"), all=F)
Newtab$relwei<-Newtab$biom1km.x/Newtab$biom1km.y #division du poid du taxon par poid total de l'annee
Test<-aggregate(relwei ~ code_trait , data = Newtab, sum)
summary(Test) ## permet de vérifier que l'abondance relative totale est bien de 1
Newtab<-Newtab[order(Newtab[,4], decreasing=F),]  ####D ordonner Newtab pour que ca soit dans le même ordre que tab
Newtab<-merge(Newtab,tab) # fusion des tables avec le tdi et avec les biomasses
#weighting tdi by relative biomass
#On applique la biomasse sur chaque indice pour avoir le nouveau TDI
Newtab$mobi<-as.numeric(Newtab$Mobility)*Newtab$relwei
Newtab$frag<-as.numeric(Newtab$Fragility)*Newtab$relwei
Newtab$posi<-as.numeric(Newtab$Position)*Newtab$relwei
Newtab$siz<-as.numeric(Newtab$Size)*Newtab$relwei
Newtab$feed<-as.numeric(Newtab$Feeding)*Newtab$relwei
Newtab$tdi2<-as.numeric(Newtab$TDI)*Newtab$relwei
#test tdi indices range 0-3 or 0-15
summary(Newtab)# le tdi est influencé maintenant par la biomasse
#aggregate per trawl
Trawltdi<- aggregate(cbind(mobi,frag,posi,siz,feed,tdi2) ~ code_trait + Annee+ Trait, data = Newtab, sum)
names(Trawltdi)<-c("code_trait", "Annee", "Trait","Mobility", "Fragility", "Position", "Size", "Feeding", "TDIm" )
### TDI par station
Trawltdi  ## jeu de donnée avec
### packages ###
library("plyr")
### vérification de la proportion de sp enlever apr station
w<- ddply(tab, .variables="code_trait", summarize, biom_tot= sum(biom1km))
q<- merge(pb, w, by="code_trait")
p <- ddply(q, .variables = "code_trait", summarize, biom_enl=sum(biom1km))
q<- merge(p, w, by="code_trait")
q$prop <- (q$biom_enl/q$biom_tot)*100
q<- subset(q, prop >= 25) ### on conserve que les taxons où moins de 25% de la biomasse a été supprimée par manque d'info
i<-unique(q$code_trait)
tab<- subset(tab, !code_trait %in% i)
#### suppression des taxons où les traits sont encore vides
if (length(pb)>0) tab <- tab[-which(is.na(tab$Mobility)),] else tab <- tab
# création de la colonne tdi
tab$TDI<-tab$Mobility + tab$Fragility + tab$Position + tab$Size + tab$Feeding.mode
# aggregate tab by trait, année et taxon
Newtab<- aggregate(biom1km ~ code_trait + Annee + taxon , data = tab, sum)
#compute total catch by trait et année
Tot<- aggregate(biom1km ~ code_trait + Annee   , data = Newtab, sum)
#compute relative biomass
Newtab<-merge(Newtab, Tot, by=c("code_trait"), all=F)
Newtab$relwei<-Newtab$biom1km.x/Newtab$biom1km.y #division du poid du taxon par poid total de l'annee
Test<-aggregate(relwei ~ code_trait , data = Newtab, sum)
summary(Test) ## permet de vérifier que l'abondance relative totale est bien de 1
Newtab<-Newtab[order(Newtab[,4], decreasing=F),]  ####D ordonner Newtab pour que ca soit dans le même ordre que tab
Newtab<-merge(Newtab,tab) # fusion des tables avec le tdi et avec les biomasses
#weighting tdi by relative biomass
#On applique la biomasse sur chaque indice pour avoir le nouveau TDI
Newtab$mobi<-as.numeric(Newtab$Mobility)*Newtab$relwei
Newtab$frag<-as.numeric(Newtab$Fragility)*Newtab$relwei
Newtab$posi<-as.numeric(Newtab$Position)*Newtab$relwei
Newtab$siz<-as.numeric(Newtab$Size)*Newtab$relwei
Newtab$feed<-as.numeric(Newtab$Feeding)*Newtab$relwei
Newtab$tdi2<-as.numeric(Newtab$TDI)*Newtab$relwei
#test tdi indices range 0-3 or 0-15
summary(Newtab)# le tdi est influencé maintenant par la biomasse
#aggregate per trawl
Trawltdi<- aggregate(cbind(mobi,frag,posi,siz,feed,tdi2) ~ code_trait + Annee+ Trait, data = Newtab, sum)
names(Trawltdi)<-c("code_trait", "Annee", "Trait","Mobility", "Fragility", "Position", "Size", "Feeding", "TDIm" )
### TDI par station
Trawltdi  ## jeu de donnée avec les valeurs d
setwd("C://Users/cjac/Desktop/scripts_example/") ## charger le dossier dans lequel on travaille
### packages ###
library("plyr")
##### Chargement des tableaux de données ###
donnee_medits200 <- read.table("data_bio.csv", header=T, sep=";", dec=".") ## fichier espèces
param <- read.table("caracteristics_stations.csv", sep=";", dec=".", header=T)  ### fichier position des traits de chalut
TDI<- read.table("TDI_all.csv", sep=";", dec=",", header=T)  ## fichier traits biologiques/espèces
#### Trawling Disturbance Impact (Foveau et al., 2017) ####
###### Correspondance entre le fichier final et la base de données des traits des espèces
### merge catch and tdi
TDI$Taxon <- as.character(TDI$Taxon)
tab<- merge(donnee_medits200,TDI, by.x="taxon", by.y="Taxon", all.x=T, all.y=F)
#### quels sont les taxons où il manque le tdi
tab$taxon<- as.character(tab$taxon)
tabx<-tab[which(is.na(tab$Mobility)),]
b<-unique(tabx$taxon)  #### nom des taxons n'ayant pas de traits
a<-merge(tabx, TDI, by.x="taxon", by.y="Family", all.x=T, all.y=F)
match(b, TDI$Family) ### ici on fait au niveau de la famille mais on peut le faire au niveau taxonomique que l'on veut
pb <- c()  #### création d'un vecteur vide pb
for(i in 1:length(b)){
taxon=b[i]     #### taxon = nom des taxons n'ayant pas de traits
Trait = TDI[which(TDI$Family==taxon),c(7:11)] #### création du data frame Trait qui prends les valeurs de traits si la famille est retrouvée dans la catégorie famille du tbaleau TDI
Trait=unique(Trait)  ### permet de garder "qu'un exemplaire" des diférences
if(nrow(Trait)==1){tab[which(tab$taxon==taxon), c(18:23)]<- Trait}  ### Trait comporte qu'une ligne alors on peut lui attribuer les valeurs de Trait
if(nrow(Trait)>1){  #### Trait comporte plusieurs lignes
if(as.numeric(apply(Trait[1:5],2, sd))[1]<1.5 & as.numeric(apply(Trait,2, sd))[2]<1.5 & as.numeric(apply(Trait,2, sd))[3]<1.5 & as.numeric(apply(Trait,2, sd))[4]<1.5 & as.numeric(apply(Trait,2, sd))[5]<1.5)   {  ### l'écart type de chaque trait doit être inférieur à 1.5
if(sd(as.numeric(apply(Trait,1, sum)))<2.5){   #### l'écart type de la somme des traits (donc du TDI) doit être inférieur à 2.5
pb <- rbind(pb, taxon)  #### tout les taxons qui répondent à ces conditions vont se retrouver dans pb
Trait[nrow(Trait)+1,] <-apply(Trait,2,max)  #### si toutes ces conditions réunient alors on peut prendre la valeur maximale pour chaque trait et l'attribuer à la famille
tab[which(tab$taxon==taxon), c(18:24)]<- Trait[nrow(Trait),]  #### et on peut le remettre dans le tableau du départ
}
}
}
}
pb<- tab[which(is.na(tab$Mobility)),] #### permet de savoir quels taxons ont été enlevé
### vérification de la proportion de sp enlever apr station
w<- ddply(tab, .variables="code_trait", summarize, biom_tot= sum(biom1km))
q<- merge(pb, w, by="code_trait")
p <- ddply(q, .variables = "code_trait", summarize, biom_enl=sum(biom1km))
q<- merge(p, w, by="code_trait")
q$prop <- (q$biom_enl/q$biom_tot)*100
q<- subset(q, prop >= 25) ### on conserve que les taxons où moins de 25% de la biomasse a été supprimée par manque d'info
i<-unique(q$code_trait)
tab<- subset(tab, !code_trait %in% i)
#### suppression des taxons où les traits sont encore vides
if (length(pb)>0) tab <- tab[-which(is.na(tab$Mobility)),] else tab <- tab
# création de la colonne tdi
tab$TDI<-tab$Mobility + tab$Fragility + tab$Position + tab$Size + tab$Feeding.mode
# aggregate tab by trait, année et taxon
Newtab<- aggregate(biom1km ~ code_trait + Annee + taxon , data = tab, sum)
#compute total catch by trait et année
Tot<- aggregate(biom1km ~ code_trait + Annee   , data = Newtab, sum)
#compute relative biomass
Newtab<-merge(Newtab, Tot, by=c("code_trait"), all=F)
Newtab$relwei<-Newtab$biom1km.x/Newtab$biom1km.y #division du poid du taxon par poid total de l'annee
Test<-aggregate(relwei ~ code_trait , data = Newtab, sum)
summary(Test) ## permet de vérifier que l'abondance relative totale est bien de 1
Newtab<-Newtab[order(Newtab[,4], decreasing=F),]  ####D ordonner Newtab pour que ca soit dans le même ordre que tab
Newtab<-merge(Newtab,tab) # fusion des tables avec le tdi et avec les biomasses
#weighting tdi by relative biomass
#On applique la biomasse sur chaque indice pour avoir le nouveau TDI
Newtab$mobi<-as.numeric(Newtab$Mobility)*Newtab$relwei
Newtab$frag<-as.numeric(Newtab$Fragility)*Newtab$relwei
Newtab$posi<-as.numeric(Newtab$Position)*Newtab$relwei
Newtab$siz<-as.numeric(Newtab$Size)*Newtab$relwei
Newtab$feed<-as.numeric(Newtab$Feeding)*Newtab$relwei
Newtab$tdi2<-as.numeric(Newtab$TDI)*Newtab$relwei
#test tdi indices range 0-3 or 0-15
summary(Newtab)# le tdi est influencé maintenant par la biomasse
#aggregate per trawl
Trawltdi<- aggregate(cbind(mobi,frag,posi,siz,feed,tdi2) ~ code_trait + Annee+ Trait, data = Newtab, sum)
names(Trawltdi)<-c("code_trait", "Annee", "Trait","Mobility", "Fragility", "Position", "Size", "Feeding", "TDIm" )
### TDI par station
Trawltdi  ## jeu de donnée avec les valeurs de TDI par station
t<- unique(Newtab$taxon)
g5<-subset(Newtab, TDI>13)  #### formation du groupe g5
g4 <- subset(Newtab, TDI>10 & TDI<14) #### groupe g5 + g4
g3 <- subset(Newtab, TDI<11 & TDI>7)
g2<- subset(Newtab, TDI<8 & TDI>4)
g1 <- subset(Newtab, TDI<5)
#### calcul de l'abondance de chaque groupe à chaque station
g5_ab<-ddply(g5, .variables = c("code_trait"), summarize, biomg5=sum(relwei))
g4_ab<-ddply(g4, .variables = c("code_trait"), summarize, biomg4=sum(relwei))
g3_ab<-ddply(g3, .variables = c("code_trait"), summarize, biomg3=sum(relwei))
g2_ab<-ddply(g2, .variables = c("code_trait"), summarize, biomg2=sum(relwei))
g1_ab<-ddply(g1, .variables = c("code_trait"), summarize, biomg1=sum(relwei))
#### calcul de l'abondance totale de chaque station
ab_tot <- ddply(Newtab, .variables = c("code_trait"), summarize, abontot=sum(densite1km), biomtot=sum(relwei))
ab_tot<-merge(ab_tot, g5_ab, by="code_trait", all.x = T , all.y=F)
ab_tot<-merge(ab_tot, g4_ab, by="code_trait", all.x = T , all.y=F)
ab_tot<-merge(ab_tot, g3_ab, by="code_trait", all.x = T , all.y=F)
ab_tot<-merge(ab_tot, g2_ab, by="code_trait", all.x = T , all.y=F)
ab_tot<-merge(ab_tot, g1_ab, by="code_trait", all.x = T , all.y=F)
ab_tot <-replace(ab_tot, is.na(ab_tot),0)  ### remplacement des NA par 0
#### calcul du TDI #####
ab_tot$TDI = (log(1)*log(ab_tot$biomg1 + 1) +log(2) *log(ab_tot$biomg2  + 1) + log(4) * log(ab_tot$biomg3  +1) +
log(8)*log(ab_tot$biomg4  +1) + log(16)*log(ab_tot$biomg5  +1 ))/log(ab_tot$biomtot +1) ## jeu de donnée avec les valeurs de TDI de de Juan par station
ab_tot<- merge(ab_tot, param, by="code_trait")
ab_tot
## création d'une table avec uniquement les espèces des groupes 3, 4 et 5
tab2<- subset (tab, TDI >7)
# aggregate tab by taxon,haul, year
Newtab2<- aggregate(biom1km ~ code_trait+ Annee + taxon , data = tab2, sum)
#compute total catch by haul, year
Tot2<- aggregate(biom1km ~ code_trait + Annee  , data = Newtab2, sum)
#compute relative biomass
Newtab3<-merge(Newtab2, Tot2, by=c("code_trait"), all=F)
Newtab3$relwei<-Newtab3$biom1km.x/Newtab3$biom1km.y #division du poid du taxon par poid total de l'annee
Test<-aggregate(relwei ~ code_trait , data = Newtab3, sum)
summary(Test)
Newtab3<-Newtab3[order(Newtab3[,4], decreasing=F),]  ####D ordonner Newtab3 pour que ca soit dans le même ordre que tab
Newtab3<-merge(Newtab3,tab2) # fusion des tables avec le tdi et avec les biomasses
#weighting tdi by relative biomass
#On applique la biomasse sur chaque indice pour avoir le nouveau TDI
Newtab3$mobi<-as.numeric(Newtab3$Mobility)*Newtab3$relwei
Newtab3$frag<-as.numeric(Newtab3$Fragility)*Newtab3$relwei
Newtab3$siz<-as.numeric(Newtab3$Size)*Newtab3$relwei
Newtab3$feed<-as.numeric(Newtab3$Feeding)*Newtab3$relwei
Newtab3$tdi2<-as.numeric(Newtab3$TDI)*Newtab3$relwei
#test tdi indices range 0-3 or 0-15
summary(Newtab3)# le tdi est influencé maintenant par la biomasse
Newtab3$posi<-as.numeric(Newtab3$Position)*Newtab3$relwei
#aggregate per trawl
Trawltdi_A_3_4_5<- aggregate(cbind(mobi,frag,posi,siz,feed,tdi2) ~ code_trait + Annee + Trait, data = Newtab3, sum)
names(Trawltdi_A_3_4_5)<-c("code_trait", "Annee","Trait", "Mobility", "Fragility", "Position", "Size", "Feeding", "TDI_p" )
data <- tab [,c(1,2,10, 18:23)]  ## on conserve que les colonnes du fichier tab qui nous intéressent
### TDI par station
Trawltdi_A_3_4_5 ## jeu de donnée avec les valeurs de pTDI pour chaque station
### remise des valeurs de traits entre 0 et 1
data$Mobility <- (data$Mobility+1)/4
data$Fragility <- as.numeric(data$Fragility)
data$Fragility <- (data$Fragility+1)/4
data$Size <- (data$Size+1)/4
data$Position<- (data$Position+1)/4
data$Feeding.mode <- (data$Feeding.mode+1)/4
data$VME <- data$VME/4  ## statut de protection (VME pour med et liste ospar pour Atlantique cf. base de traits)
a= data$Mobility*data$Position*data$Size  ### on a choisit que la mobilité, la position et la taille était des facteurs de sensibilité direct primaire
g=data$Fragility  ### et la fragilité un facteur direct aggravant
Vul.fct<-function(a,g,gamma=0.5){return(a^(1-(g/(g+gamma))))}
data$ti<- Vul.fct(a,g,gamma = 0.5)
b=(data$VME+data$Feeding.mode)/2   ### le statut de protection et le mode d'alimentation sont des facteurs indirects primaires
data$si<- Vul.fct(b, 0, gamma=0.5)
data<- merge(data, ab_rel, by="code_trait")
data$ab_relat<- data$biom1km/data$ab_tot  ## permet d'avoir l'abondance relative
data$tisi <- data$si*data$ti
data$vulnerabilite_sp <- data$ab_relat/(data$tisi)
ab_rel<- ddply(data, .variables=c("code_trait"), summarize, ab_tot = sum(biom1km))
## Calcul du Dj
vulne_sp_positive<- ddply(data, .variables=c("code_trait"), summarize, Dj_1=-sum(vulnerabilite_sp))
tab
data <- tab [,c(1,2,10, 18:23)]  ## on conserve que les colonnes du fichier tab qui nous intéressent
### remise des valeurs de traits entre 0 et 1
data$Mobility <- (data$Mobility+1)/4
data$Fragility <- as.numeric(data$Fragility)
data$Fragility <- (data$Fragility+1)/4
data$Size <- (data$Size+1)/4
data$Position<- (data$Position+1)/4
data$Feeding.mode <- (data$Feeding.mode+1)/4
data$VME <- data$VME/4  ## statut de protection (VME pour med et liste ospar pour Atlantique cf. base de traits)
a= data$Mobility*data$Position*data$Size  ### on a choisit que la mobilité, la position et la taille était des facteurs de sensibilité direct primaire
g=data$Fragility  ### et la fragilité un facteur direct aggravant
Vul.fct<-function(a,g,gamma=0.5){return(a^(1-(g/(g+gamma))))}
data$ti<- Vul.fct(a,g,gamma = 0.5)
b=(data$VME+data$Feeding.mode)/2   ### le statut de protection et le mode d'alimentation sont des facteurs indirects primaires
data$si<- Vul.fct(b, 0, gamma=0.5)
ab_rel<- ddply(data, .variables=c("code_trait"), summarize, ab_tot = sum(biom1km))
data<- merge(data, ab_rel, by="code_trait")
data$ab_relat<- data$biom1km/data$ab_tot  ## permet d'avoir l'abondance relative
data$tisi <- data$si*data$ti
data$vulnerabilite_sp <- data$ab_relat/(data$tisi)
## Calcul du Dj
vulne_sp_positive<- ddply(data, .variables=c("code_trait"), summarize, Dj_1=-sum(vulnerabilite_sp))
vulne_sp_positive  ### tableaux de données avec les valeurs de mT pour chacune des stations échantillonnées
